# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gSdolm0q_zgFtSAlqRJSdEBXkyPJqPs4
"""

from google.colab import drive
drive.mount('/content/drive')

cd drive/MyDrive/NMIMS/yolo

ls

import cv2
import time
import numpy as np
from google.colab.patches import cv2_imshow

# Set the confidence and NMS threshold values
confidence = 0.6
Nms = 0.3

# Load the class names from the COCO dataset
class_names = []
with open("coco.names", "r") as f:
    class_names = [cname.strip() for cname in f.readlines()]

# Load the input image
img = cv2.imread("image.jpg")

# Load YOLOv4 model and configure for GPU acceleration
arc = cv2.dnn.readNet("yolov4.weights", "yolov4.cfg")
arc.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
arc.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16)
model = cv2.dnn_DetectionModel(arc)
model.setInputParams(size=(640, 640), scale=1/255, swapRB=True)

# Measure the time taken for inference
x = time.time()
classes, scores, boxes = model.detect(img, confidence, Nms)
y = time.time()
fps = 1 / (y - x)

# Process detected people and draw bounding boxes
for (classid, score, box) in zip(classes, scores, boxes):
    classid_value = classid  # Extract class index
    class_name = class_names[classid_value]  # Get the class name using the index

    if class_name == "person":
        label = "Person : %.2f" % score
        cv2.rectangle(img, box, color=(255, 200, 10), thickness=2)
        cv2.putText(img, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (25, 55, 255), 2)

# Display the image with FPS information
cv2.putText(img, "FPS:{0:.2f}".format(fps), (20, 25), cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=(255, 0, 0), thickness=2)
cv2_imshow(img)

